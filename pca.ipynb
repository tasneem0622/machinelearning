{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0].reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2826b1f71d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.gray()\n",
    "plt.matshow(digits.data[7].reshape(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0        0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1        0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2        0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3        0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4        0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "\n",
       "   pixel_7_6  pixel_7_7  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        9.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(digits.data,columns=digits.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df\n",
    "y=digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.33501649, -0.04308102, ..., -1.14664746,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  0.54856067,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  1.56568555,\n",
       "         1.6951369 , -0.19600752],\n",
       "       ...,\n",
       "       [ 0.        , -0.33501649, -0.88456568, ..., -0.12952258,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -0.67419451, ...,  0.8876023 ,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649,  1.00877481, ...,  0.8876023 ,\n",
       "        -0.26113572, -0.19600752]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled=scaler.fit_transform(x)\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tasneem Fathima\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9611111111111111"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 29)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca=pca.fit_transform(x)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14890594, 0.13618771, 0.11794594, 0.08409979, 0.05782415,\n",
       "       0.0491691 , 0.04315987, 0.03661373, 0.03353248, 0.03078806,\n",
       "       0.02372341, 0.02272697, 0.01821863, 0.01773855, 0.01467101,\n",
       "       0.01409716, 0.01318589, 0.01248138, 0.01017718, 0.00905617,\n",
       "       0.00889538, 0.00797123, 0.00767493, 0.00722904, 0.00695889,\n",
       "       0.00596081, 0.00575615, 0.00515158, 0.0048954 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca,X_test_pca,y_train_pca,y_test_pca=train_test_split(X_pca,y,test_size=0.2,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694444444444444"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_pca,y_train_pca)\n",
    "model.score(X_test_pca,y_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
